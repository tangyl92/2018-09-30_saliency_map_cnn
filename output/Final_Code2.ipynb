{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final Code2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fmbNzcLI8c6M",
        "colab_type": "code",
        "outputId": "b79c86a2-af02-46dc-8f5d-e48b334477c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "% matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import math\n",
        "import PIL.Image\n",
        "import time\n",
        "import os\n",
        "\n",
        "from __future__ import print_function\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.applications import vgg16\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras import regularizers\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JGBegv6i8JLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### dataset contains five classes from ImageNet\n",
        "x_test = np.load(\"X_test.npy\")\n",
        "x_train = np.load(\"X_train.npy\")\n",
        "y_test_index = np.load(\"y_test.npy\") - 1\n",
        "y_train_index = np.load(\"y_train.npy\") - 1\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train_index, 5)\n",
        "y_test = keras.utils.to_categorical(y_test_index, 5)\n",
        "\n",
        "x_combine = np.concatenate((x_train, x_test), axis = 0)\n",
        "y_combine = list(np.concatenate((y_train_index, y_test_index), axis = 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSM6ik_pGTEE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
        "  \n",
        "\n",
        "def deprocess_image(x):\n",
        "    # normalize an image: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + K.epsilon())\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JiTV4G_Nx7x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization on VGG16 model of Imagenet Dataset"
      ]
    },
    {
      "metadata": {
        "id": "EzLPR1MkNkD4",
        "colab_type": "code",
        "outputId": "f72ffbbc-8c58-4217-8bec-0b42c9571217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "# build the VGG16 network with ImageNet weights\n",
        "model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
        "print('Model loaded.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n",
            "Model loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNCEoyDrvSVi",
        "colab_type": "code",
        "outputId": "960422ff-618a-44d1-acfc-fbe72ae7396f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fc5a83272e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "lxvN7C_hOEzb",
        "colab_type": "code",
        "outputId": "2ed5feec-b223-48be-a035-6cdd7db0328f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "# this is the placeholder for the input images\n",
        "input_img = model.input\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k4-aVb-AOO8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define funtion of saliency map for convolutional layer\n",
        "def saliency_map(layer_name,iter = 20, n_filters = 200,  n = 8, \n",
        "                 img_width = 224, img_height = 224,\n",
        "                 layder_dict = layer_dict,save = True): \n",
        "    kept_filters = []\n",
        "    for filter_index in range(n_filters):\n",
        "      # we only scan through the first n filters,\n",
        "      # since sometimes there are too many of them\n",
        "      print('Processing filter %d' % filter_index)\n",
        "      start_time = time.time()\n",
        "\n",
        "      # we build a loss function that maximizes the activation\n",
        "      # of the nth filter of the layer considered\n",
        "      layer_output = layer_dict[layer_name].output\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          loss = K.mean(layer_output[:, filter_index, :, :])\n",
        "      else:\n",
        "          loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "      # we compute the gradient of the input picture wrt this loss\n",
        "      grads = K.gradients(loss, input_img)[0]\n",
        " \n",
        "      # normalization trick: we normalize the gradient\n",
        "      grads = normalize(grads)\n",
        "\n",
        "      # this function returns the loss and grads given the input picture\n",
        "      iterate = K.function([input_img], [loss, grads])\n",
        "\n",
        "      # step size for gradient ascent\n",
        "      step = 1.\n",
        "\n",
        "      # we start from a gray image with some random noise\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
        "      else:\n",
        "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
        "      input_img_data = (input_img_data - 0.5) * 20 + 128\n",
        "\n",
        "      # we run gradient ascent for n steps, here we use 20\n",
        "      for i in range(iter):\n",
        "          loss_value, grads_value = iterate([input_img_data])\n",
        "          input_img_data += grads_value * step\n",
        "\n",
        "          print('Current loss value:', loss_value)\n",
        "          if loss_value <= 0.:\n",
        "              # some filters get stuck to 0, we can skip them\n",
        "              break\n",
        "\n",
        "      # decode the resulting input image\n",
        "      if loss_value > 0:\n",
        "          img = deprocess_image(input_img_data[0])\n",
        "          kept_filters.append((img, loss_value))\n",
        "      end_time = time.time()\n",
        "      print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
        "\n",
        "    # we will stich the best 64 filters on a 8 x 8 grid.\n",
        "\n",
        "    # the filters that have the highest loss are assumed to be better-looking.\n",
        "    # we will only keep the top n*n filters.\n",
        "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
        "    kept_filters = kept_filters[:n * n]\n",
        "\n",
        "    # build a black picture with enough space in between\n",
        "    margin = 5\n",
        "    width = n * img_width + (n - 1) * margin\n",
        "    height = n * img_height + (n - 1) * margin\n",
        "    stitched_filters = np.zeros((width, height, 3))\n",
        "\n",
        "    # fill the picture with our saved filters\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            img, loss = kept_filters[i * n + j]\n",
        "            width_margin = (img_width + margin) * i\n",
        "            height_margin = (img_height + margin) * j\n",
        "            stitched_filters[\n",
        "                width_margin: width_margin + img_width,\n",
        "                height_margin: height_margin + img_height, :] = img\n",
        "    if save:\n",
        "        # save the result to disk\n",
        "        save_img('stitched_filters_%dx%d_%s.png' % (n, n, layer_name), stitched_filters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xae6F7xfp92K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saliency_map(layer_name = 'block5_conv1', iter = 20, n = 8, layder_dict = layer_dict)\n",
        "# saliency_map(layer_name = 'block1_conv1', n_filters = 64, iter = 20, n = 8, layder_dict = layer_dict)\n",
        "saliency_map(layer_name = 'block1_conv2', n_filters = 64, iter = 20, n = 5, layder_dict = layer_dict)\n",
        "# saliency_map(layer_name = 'block2_conv1', n_filters = 64, iter = 20, n = 5, layder_dict = layer_dict)\n",
        "saliency_map(layer_name = 'block2_conv2', n_filters = 64, iter = 20, n = 5, layder_dict = layer_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyQ0a_hLR2vp",
        "colab_type": "code",
        "outputId": "2a8df277-9b63-4662-f7ef-aa71252caf04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model = vgg16.VGG16(weights='imagenet', include_top=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 35s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nu8zNfIW687l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initial(index):\n",
        "  selected = [i for i in range(len(y_combine)) if y_combine[i] == index]\n",
        "  return np.mean(x_combine[selected], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9lwRrk_xOtTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize_softmax_dense_VGG(model, iter, output_index = 0, step = 0.5,\n",
        "                                alpha = 0.1, initialize = 'random',\n",
        "                                initialize_index = 0, save = True):\n",
        "    # model: loaded model\n",
        "    # step: step size for gradient ascent\n",
        "    # alpha: panelty coefficient of the loss function\n",
        "    # initialize: 'random' or 'mean'. If 'random', initialize input data at\n",
        "    #              random; else intialize with the mean of all the images in\n",
        "    #              this class on each pixel\n",
        "    # initialize_index: only effective when initialize = 'mean', set sample\n",
        "    #                   index for a particular class\n",
        "  \n",
        "    # dimensions of the generated pictures for each filter.\n",
        "    img_width = 224\n",
        "    img_height = 224\n",
        "\n",
        "    # this is the placeholder for the input images\n",
        "    input_img = model.input\n",
        "\n",
        "    #find the score value before softmax activation:\n",
        "    #1.recreate the dense layer\n",
        "    fc_output = model.layers[-2].output\n",
        "    outDense = Dense(1000, name='newDense', use_bias = True)(fc_output)\n",
        "\n",
        "    #2.create the new model\n",
        "    checkingModel = Model(model.inputs, outDense)\n",
        "\n",
        "    wgts = model.layers[-1].get_weights()\n",
        "    checkingModel.get_layer('newDense').set_weights(wgts)\n",
        "\n",
        "    model_output = checkingModel.output\n",
        "\n",
        "    # we build a loss function that maximizes the activation\n",
        "    loss = model_output[:, output_index] - alpha * tf.norm(input_img)\n",
        "    \n",
        "    # we compute the gradient of the input picture wrt this loss\n",
        "    grads = K.gradients(loss, input_img)[0]\n",
        "\n",
        "    # normalization trick: we normalize the gradient\n",
        "    grads = normalize(grads)\n",
        "\n",
        "    # this function returns the loss and grads given the input picture\n",
        "    iterate = K.function([input_img], [loss, grads])\n",
        "\n",
        "    # we start from a gray image with some random noise\n",
        "    if initialize == 'random':\n",
        "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
        "    elif initialize == 'mean':\n",
        "        input_img_data = initial(initialize_index)\n",
        "        input_img_data = np.expand_dims(input_img_data, axis = 0)\n",
        "    else:\n",
        "        raise ValueError('Initialization method should be \"random\" or \"mean\".')\n",
        "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
        "\n",
        "    # we run gradient ascent for 20 steps\n",
        "    for i in range(iter):\n",
        "        loss_value, grads_value = iterate([input_img_data])\n",
        "        input_img_data += grads_value * step\n",
        "        print('Current loss value for %d:' % i, loss_value)\n",
        "    \n",
        "    if save:\n",
        "      if initialize == 'random':\n",
        "          img = deprocess_image(input_img_data[0])\n",
        "          if os.path.exists(\"final_image_VGG_random_%s.png\" % (str(output_index))):\n",
        "            os.remove('final_image_VGG_random_%s.png' % (str(output_index)))\n",
        "          save_img('final_image_VGG_random_%s.png' % (str(output_index)) , img)\n",
        "      else:\n",
        "          img = deprocess_image(input_img_data[0])\n",
        "          if os.path.exists(\"final_image_VGG_mean_%s.png\" % (str(output_index))):\n",
        "            os.remove('final_image_VGG_mean_%s.png' % (str(output_index)))\n",
        "          save_img('final_image_VGG_mean_%s.png' % (str(output_index)) , img)\n",
        "          \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPw3Eoh4SOcX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize_softmax_dense_VGG(model = model, iter = 200, output_index = 1) # goldfish\n",
        "visualize_softmax_dense_VGG(model = model, iter = 200, output_index = 248) # husky\n",
        "visualize_softmax_dense_VGG(model = model, iter = 300, output_index = 951) # lemon \n",
        "visualize_softmax_dense_VGG(model = model, iter = 300, output_index = 9) # ostrich\n",
        "visualize_softmax_dense_VGG(model = model, iter = 200, output_index = 55) # snake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rq-gGM2oGw00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize_softmax_dense_VGG(model = model, iter = 2000, output_index = 1,\n",
        "                            initialize = 'mean', initialize_index = 0) # goldfish\n",
        "visualize_softmax_dense_VGG(model = model, iter = 2000, output_index = 248,\n",
        "                            initialize = 'mean', initialize_index = 1) # husky\n",
        "visualize_softmax_dense_VGG(model = model, iter = 2000, output_index = 951,\n",
        "                            initialize = 'mean', initialize_index = 2) # lemon\n",
        "visualize_softmax_dense_VGG(model = model, iter = 2000, output_index = 9,\n",
        "                            initialize = 'mean', initialize_index = 3) # ostrich\n",
        "visualize_softmax_dense_VGG(model = model, iter = 2000, output_index = 55,\n",
        "                            initialize = 'mean', initialize_index = 4) # snake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dr7vcMLK8M4R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Training on 5-class Imagenet Dataset"
      ]
    },
    {
      "metadata": {
        "id": "8AShrJcJ8k43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "batch_size = 128\n",
        "input_shape = x_train.shape[1:]\n",
        "epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVpUY5TV8qZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start construction of the Keras Sequential model.\n",
        "model = Sequential()\n",
        "\n",
        "# First convolutional layer with ReLU-activation and max-pooling.\n",
        "model.add(keras.layers.Conv2D(filters = 32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape= input_shape, padding = \"same\", name = 'layer_conv1'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides = 2, name = 'max_pool1', padding = \"same\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# Second convolutional layer with ReLU-activation and max-pooling.\n",
        "model.add(keras.layers.Conv2D(filters = 64, kernel_size=(3, 3),\n",
        "                 activation='relu', padding = \"same\", name = 'layer_conv2'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides = 2, padding = \"same\", name = 'max_pool2'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# Third convolutional layer with ReLU-activation and max-pooling.\n",
        "model.add(keras.layers.Conv2D(filters = 128, kernel_size=(5, 5),\n",
        "                 activation='relu', padding = \"same\", name = 'layer_conv3'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides = 2, padding = \"same\", name = 'max_pool3'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# Forth convolutional layer with ReLU-activation and max-pooling.\n",
        "model.add(keras.layers.Conv2D(filters = 128, kernel_size=(5, 5),\n",
        "                 activation='relu', padding = \"same\", name = 'layer_conv4'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides = 2, padding = \"same\", name = 'max_pool4'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "# Flatten\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# fully connected layers\n",
        "model.add(keras.layers.Dense(128, activation='relu', name = 'fc_layer1'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(5, use_bias = True, name = 'fc_layer3'))\n",
        "model.add(keras.layers.Softmax())\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= \"adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WPuqxCky8yry",
        "colab_type": "code",
        "outputId": "fb045fcb-75fe-4325-a94d-ba44046b8fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs= epochs)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2312/2312 [==============================] - 12s 5ms/step - loss: 1.1484 - acc: 0.6224\n",
            "Epoch 2/5\n",
            "2312/2312 [==============================] - 8s 4ms/step - loss: 0.6060 - acc: 0.7829\n",
            "Epoch 3/5\n",
            "2312/2312 [==============================] - 8s 4ms/step - loss: 0.5361 - acc: 0.8049\n",
            "Epoch 4/5\n",
            "2312/2312 [==============================] - 8s 4ms/step - loss: 0.4577 - acc: 0.8369\n",
            "Epoch 5/5\n",
            "2312/2312 [==============================] - 8s 4ms/step - loss: 0.3382 - acc: 0.8793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6504743482827315, 0.801038062283737]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "PGoyS_M183BV",
        "colab_type": "code",
        "outputId": "8be04ec8-b6aa-48ac-9906-b11af6ce4259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer_conv1 (Conv2D)         (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pool1 (MaxPooling2D)     (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "layer_conv2 (Conv2D)         (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pool2 (MaxPooling2D)     (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "layer_conv3 (Conv2D)         (None, 56, 56, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pool3 (MaxPooling2D)     (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "layer_conv4 (Conv2D)         (None, 28, 28, 128)       409728    \n",
            "_________________________________________________________________\n",
            "max_pool4 (MaxPooling2D)     (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc_layer1 (Dense)            (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "fc_layer3 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "softmax_4 (Softmax)          (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 3,848,005\n",
            "Trainable params: 3,847,045\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GJW8kq6UEI65",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization on model of 5 class Imagenet Dataset"
      ]
    },
    {
      "metadata": {
        "id": "2DzBlBF-DnOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize_softmax_dense(model, iter, output_index = 0, step = 0.5, \n",
        "                             alpha = 0.1,save = True):\n",
        "    # model: loaded model\n",
        "    # step: step size for gradient ascent\n",
        "    # alpha: panelty coefficient of the loss function\n",
        "  \n",
        "    # dimensions of the generated pictures for each filter.\n",
        "    img_width = 224\n",
        "    img_height = 224\n",
        "\n",
        "    # the name of the layer we want to visualize\n",
        "    # (see model definition at keras/applications/vgg16.py)\n",
        "    # this is the placeholder for the input images\n",
        "    input_img = model.input\n",
        "\n",
        "    #find the value before softmax activation and get its output:\n",
        "    model_output = model.layers[-2].output\n",
        "    #or should this be the output from the dropout? Whichever comes immediately after the last Dense(1)\n",
        "\n",
        "    # we build a loss function that maximizes the activation\n",
        "    loss = model_output[:, output_index] - alpha * tf.norm(input_img)\n",
        "    \n",
        "    # we compute the gradient of the input picture wrt this loss\n",
        "    grads = K.gradients(loss, input_img)[0]\n",
        "\n",
        "    # normalization trick: we normalize the gradient\n",
        "    grads = normalize(grads)\n",
        "\n",
        "    # this function returns the loss and grads given the input picture\n",
        "    iterate = K.function([input_img], [loss, grads])\n",
        "\n",
        "    # step size for gradient ascent\n",
        "    # step = 0.5\n",
        "\n",
        "    # we start from a gray image with some random noise\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
        "    else:\n",
        "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
        "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
        "\n",
        "    # delta_loss = 0\n",
        "    # prev_loss_value = 0\n",
        "\n",
        "    # we run gradient ascent for 20 steps\n",
        "    for i in range(iter):\n",
        "        loss_value, grads_value = iterate([input_img_data])\n",
        "        input_img_data += grads_value * step\n",
        "        print('Current loss value for %d:' % i, loss_value)\n",
        "    \n",
        "    if save:\n",
        "      img = deprocess_image(input_img_data[0])\n",
        "      if os.path.exists(\"final_image_%s.png\" % (str(output_index))):\n",
        "        os.remove('final_image_%s.png' % (str(output_index)))\n",
        "      save_img('final_image_%s.png' % (str(output_index)) , img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRV_arSVKhLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize_softmax_dense(model = model, iter = 500, output_index = 0, step = 0.1, alpha = 0)\n",
        "visualize_softmax_dense(model = model, iter = 100, output_index = 2, step = 0.2, alpha = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}